# This file is derived from [Atlas](https://github.com/magicleap/Atlas).
# Originating Author: Zak Murez (zak.murez.com)
# Modified for [SHINEMapping] by Yue Pan.

# Original header:
# Copyright 2020 Magic Leap, Inc.

# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at

#     http://www.apache.org/licenses/LICENSE-2.0

# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.


import open3d as o3d
import numpy as np

def eval_mesh(file_pred, file_trgt, down_sample_res=0.02, threshold=0.05, truncation_acc=0.50, truncation_com=0.50, gt_bbx_mask_on= True, 
              mesh_sample_point=10000000, possion_sample_init_factor=5):
    """ Compute Mesh metrics between prediction and target.
    Opens the Meshs and runs the metrics
    Args:
        file_pred: file path of prediction (should be mesh)
        file_trgt: file path of target (shoud be point cloud)
        down_sample_res: use voxel_downsample to uniformly sample mesh points
        threshold: distance threshold used to compute precision/recall
        truncation_acc: points whose nearest neighbor is farther than the distance would not be taken into account (take pred as reference)
        truncation_com: points whose nearest neighbor is farther than the distance would not be taken into account (take trgt as reference)
        gt_bbx_mask_on: use the bounding box of the trgt as a mask of the pred mesh
        mesh_sample_point: number of the sampling points from the mesh
        possion_sample_init_factor: used for possion uniform sampling, check open3d for more details (deprecated)
    Returns:

    Returns:
        Dict of mesh metrics (chamfer distance, precision, recall, f1 score, etc.)
    """

    mesh_pred = o3d.io.read_triangle_mesh(file_pred)

    pcd_trgt = o3d.io.read_point_cloud(file_trgt)

    # (optional) filter the prediction outside the gt bounding box (since gt sometimes is not complete enough)
    if gt_bbx_mask_on: 
        trgt_bbx = pcd_trgt.get_axis_aligned_bounding_box()
        min_bound = trgt_bbx.get_min_bound()
        min_bound[2]-=down_sample_res
        max_bound = trgt_bbx.get_max_bound()
        max_bound[2]+=down_sample_res
        trgt_bbx = o3d.geometry.AxisAlignedBoundingBox(min_bound, max_bound) 
        mesh_pred = mesh_pred.crop(trgt_bbx)
        # pcd_sample_pred = pcd_sample_pred.crop(trgt_bbx)

    # pcd_sample_pred = mesh_pred.sample_points_poisson_disk(number_of_points=mesh_sample_point, init_factor=possion_sample_init_factor)
    # mesh uniform sampling
    pcd_sample_pred = mesh_pred.sample_points_uniformly(number_of_points=mesh_sample_point)

    if down_sample_res > 0:
        pred_pt_count_before = len(pcd_sample_pred.points)
        pcd_pred = pcd_sample_pred.voxel_down_sample(down_sample_res)
        pcd_trgt = pcd_trgt.voxel_down_sample(down_sample_res)
        pred_pt_count_after = len(pcd_pred.points)
        print("Predicted mesh unifrom sample: ", pred_pt_count_before, " --> ", pred_pt_count_after, " (", down_sample_res, "m)")
    
    verts_pred = np.asarray(pcd_pred.points)
    verts_trgt = np.asarray(pcd_trgt.points)

    _, dist_p = nn_correspondance(verts_trgt, verts_pred, truncation_acc, True) # find nn in ground truth samples for each predict sample -> precision related
    _, dist_r = nn_correspondance(verts_pred, verts_trgt, truncation_com, False) # find nn in predict samples for each ground truth sample -> recall related
    
    dist_p = np.array(dist_p)
    dist_r = np.array(dist_r)

    dist_p_s = np.square(dist_p)
    dist_r_s = np.square(dist_r)

    dist_p_mean = np.mean(dist_p)
    dist_r_mean = np.mean(dist_r) 

    dist_p_s_mean = np.mean(dist_p_s)
    dist_r_s_mean = np.mean(dist_r_s) 

    chamfer_l1 = 0.5 * (dist_p_mean + dist_r_mean)
    chamfer_l2 = np.sqrt(0.5 * (dist_p_s_mean + dist_r_s_mean))

    precision = np.mean((dist_p < threshold).astype('float')) * 100.0 # %
    recall = np.mean((dist_r < threshold).astype('float')) * 100.0 # %
    fscore = 2 * precision * recall / (precision + recall) # %
    
    metrics = {'MAE_accuracy (m)': dist_p_mean,
               'MAE_completeness (m)': dist_r_mean,
               'Chamfer_L1 (m)': chamfer_l1,
               'Chamfer_L2 (m)': chamfer_l2, 
               'Precision [Accuracy] (%)': precision, 
               'Recall [Completeness] (%)': recall,
               'F-score (%)': fscore, 
               'Spacing (m)': down_sample_res,  # evlaution setup
               'Inlier_threshold (m)': threshold,  # evlaution setup
               'Outlier_truncation_acc (m)': truncation_acc, # evlaution setup
               'Outlier_truncation_com (m)': truncation_com  # evlaution setup
               }
    return metrics


def nn_correspondance(verts1, verts2, truncation_dist, ignore_outlier=True):
    """ for each vertex in verts2 find the nearest vertex in verts1
    Args:
        nx3 np.array's
        scalar truncation_dist: points whose nearest neighbor is farther than the distance would not be taken into account
    Returns:
        ([indices], [distances])
    """

    indices = []
    distances = []
    if len(verts1) == 0 or len(verts2) == 0:
        return indices, distances

    pcd = o3d.geometry.PointCloud()
    pcd.points = o3d.utility.Vector3dVector(verts1.astype(np.float64))
    kdtree = o3d.geometry.KDTreeFlann(pcd)

    truncation_dist_square = truncation_dist**2

    for vert in verts2:
        _, inds, dist_square = kdtree.search_knn_vector_3d(vert, 1)
        
        if dist_square[0] < truncation_dist_square:
            indices.append(inds[0])
            distances.append(np.sqrt(dist_square[0]))
        else:
            if not ignore_outlier:
                indices.append(inds[0])
                distances.append(truncation_dist)

    return indices, distances


def eval_depth(depth_pred, depth_trgt):
    """ Computes 2d metrics between two depth maps
    Args:
        depth_pred: mxn np.array containing prediction
        depth_trgt: mxn np.array containing ground truth
    Returns:
        Dict of metrics
    """
    mask1 = depth_pred > 0  # ignore values where prediction is 0 (% complete)
    mask = (depth_trgt < 10) * (depth_trgt > 0) * mask1

    depth_pred = depth_pred[mask]
    depth_trgt = depth_trgt[mask]
    abs_diff = np.abs(depth_pred - depth_trgt)
    abs_rel = abs_diff / depth_trgt
    sq_diff = abs_diff ** 2
    sq_rel = sq_diff / depth_trgt
    sq_log_diff = (np.log(depth_pred) - np.log(depth_trgt)) ** 2
    thresh = np.maximum((depth_trgt / depth_pred), (depth_pred / depth_trgt))
    r1 = (thresh < 1.25).astype('float')
    r2 = (thresh < 1.25 ** 2).astype('float')
    r3 = (thresh < 1.25 ** 3).astype('float')

    metrics = {}
    metrics['AbsRel'] = np.mean(abs_rel)
    metrics['AbsDiff'] = np.mean(abs_diff)
    metrics['SqRel'] = np.mean(sq_rel)
    metrics['RMSE'] = np.sqrt(np.mean(sq_diff))
    metrics['LogRMSE'] = np.sqrt(np.mean(sq_log_diff))
    metrics['r1'] = np.mean(r1)
    metrics['r2'] = np.mean(r2)
    metrics['r3'] = np.mean(r3)
    metrics['complete'] = np.mean(mask1.astype('float'))

    return metrics

def crop_intersection(file_gt, files_pred, out_file_crop, dist_thre=0.1, mesh_sample_point=1000000):
    """ Get the cropped ground truth point cloud according to the intersection of the predicted
    mesh by different methods
    Args:
        file_gt: file path of the ground truth (shoud be point cloud)
        files_pred: a list of the paths of different methods's reconstruction (shoud be mesh)
        out_file_crop: output path of the cropped ground truth point cloud
        dist_thre: nearest neighbor distance threshold in meter
        mesh_sample_point: number of the sampling points from the mesh
    """
    print("Load the original ground truth point cloud from:", file_gt)
    pcd_gt = o3d.io.read_point_cloud(file_gt)
    pcd_gt_pts = np.asarray(pcd_gt.points)
    dist_square_thre = dist_thre**2
    for i in range(len(files_pred)):
        cur_file_pred = files_pred[i]
        print("Process", cur_file_pred)
        cur_mesh_pred = o3d.io.read_triangle_mesh(cur_file_pred)

        cur_sample_pred = cur_mesh_pred.sample_points_uniformly(number_of_points=mesh_sample_point)
        
        cur_kdtree = o3d.geometry.KDTreeFlann(cur_sample_pred)
        
        crop_pcd_gt_pts = []
        for pt in pcd_gt_pts:
            _, _, dist_square = cur_kdtree.search_knn_vector_3d(pt, 1)
            
            if dist_square[0] < dist_square_thre:
                crop_pcd_gt_pts.append(pt)
        
        pcd_gt_pts = np.asarray(crop_pcd_gt_pts, dtype=np.float64)

    crop_pcd_gt = o3d.geometry.PointCloud()
    crop_pcd_gt.points = o3d.utility.Vector3dVector(pcd_gt_pts)
    
    print("Output the croped ground truth to:", out_file_crop)
    o3d.io.write_point_cloud(out_file_crop, crop_pcd_gt)

    
